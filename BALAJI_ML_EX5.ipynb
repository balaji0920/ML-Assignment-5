import pandas as pd
shopping_online=pd.read_csv('/home/mllab2/Desktop/onlineShop/online
_shoppers_intention.csv')
pip install pandas
shopping_online.info()
shopping_online.isnull().sum()
from sklearn import preprocessing
# Loop over each column in the DataFrame where dtype is 'object'
for col in 
shopping_online.select_dtypes(include=['object','bool']).columns:
 # Print the column name and the unique values
 print(f"{col}: {shopping_online[col].unique()}")
# Loop over each column in the DataFrame where dtype is 'object'
for col in 
shopping_online.select_dtypes(include=['object','bool']).columns:
 # Handle missing values (replace with a default value or drop rows)
 shopping_online[col].fillna('unknown', inplace=True)
 # Convert all values to strings
 shopping_online[col] = shopping_online[col].astype(str)
 # Initialize a LabelEncoder object
 label_encoder = preprocessing.LabelEncoder()
 # Fit the encoder to the unique values in the column
 label_encoder.fit(shopping_online[col].unique())
 # Transform the column using the encoder
 shopping_online[col] = label_encoder.transform(shopping_online[col])
 # Print the column name and the unique encoded values
 print(f"{col}: {shopping_online[col].unique()}")
pip install scikit-learn
import matplotlib.pyplot as plt
import seaborn as sns
correlation_matrix = shopping_online.corr()
plt.figure(figsize=(12, 10))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', 
linewidths=.5)
plt.title('Correlation Heatmap')
plt.show()
pip install matplotlib
pip install seaborn
from sklearn import metrics
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split, StratifiedKFold, 
cross_val_score, cross_validate, GridSearchCV
from sklearn.metrics import accuracy_score, precision_score, 
recall_score, f1_score, classification_report, confusion_matrix, 
roc_auc_score, make_scorer
x_o=shopping_online.drop('Revenue',axis=1)
y_o=shopping_online['Revenue']
from sklearn.model_selection import train_test_split
x_train_o,x_test_o,y_train_o,y_test_o=train_test_split(x_o,y_o,test_size
=0.2,random_state=42,stratify=y_o)
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
# Initialize the KNN classifier
knn_classifier = KNeighborsClassifier(n_neighbors=5) # You can adjust 
the number of neighbors
# Train the model
knn_classifier.fit(x_train_o, y_train_o)
# Predict on the test set
y_pred_o = knn_classifier.predict(x_test_o)
# Evaluate the model
accuracy = accuracy_score(y_test_o, y_pred_o)
print("Accuracy:", accuracy)
import numpy as np
class KNNClassifier:
 def __init__(self, k=5):
 self.k = k
 def fit(self, X, y):
 self.X_train = X
 self.y_train = y
 def predict(self, X):
 y_pred = [self._predict(x) for x in X]
 return np.array(y_pred)
 def _predict(self, x):
 distances = [np.linalg.norm(x - x_train) for x_train in self.X_train]
 k_indices = np.argsort(distances)[:self.k]
 k_nearest_labels = [self.y_train[i] for i in k_indices]
 most_common = max(set(k_nearest_labels), 
key=k_nearest_labels.count)
 return most_common
# Example usage:
# Instantiate the classifier
knn_classifier = KNNClassifier(k=5)
# Train the classifier
knn_classifier.fit(x_train_o.values, y_train_o.values)
# Predict on the test set
y_pred_o = knn_classifier.predict(x_test_o.values)
# Evaluate the model
accuracy = np.mean(y_pred_o == y_test_o.values)
print("Accuracy:", accuracy)
# Example usage:
# Instantiate the classifier
knn_classifier = KNNClassifier(k=3)
# Train the classifier
knn_classifier.fit(x_train_o.values, y_train_o.values)
# Predict on the test set
y_pred_o = knn_classifier.predict(x_test_o.values)
# Evaluate the model
accuracy = np.mean(y_pred_o == y_test_o.values)
print("Accuracy:", accuracy)
import numpy as np
class KNNClassifier:
 def __init__(self, k=5, epochs=1):
 self.k = k
 self.epochs = epochs
 def fit(self, X, y):
 self.X_train = X
 self.y_train = y
 def predict(self, X):
 y_pred = [self._predict(x) for x in X]
 return np.array(y_pred)
 def _predict(self, x):
 distances = [np.linalg.norm(x - x_train) for x_train in self.X_train]
 k_indices = np.argsort(distances)[:self.k]
 k_nearest_labels = [self.y_train[i] for i in k_indices]
 most_common = max(set(k_nearest_labels), 
key=k_nearest_labels.count)
 return most_common
 # Iterate through epochs
 for _ in range(self.epochs):
 for x, y in zip(X, y):
 self._update_weights(x, y)
# Example usage:
# Instantiate the classifier
knn_classifier = KNNClassifier(k=5, epochs=3) # Set number of epochs to 
3
# Train the classifier
knn_classifier.fit(x_train_o.values, y_train_o.values)
# Predict on the test set
y_pred_o = knn_classifier.predict(x_test_o.values)
# Evaluate the model
accuracy = np.mean(y_pred_o == y_test_o.values)
print("Accuracy:", accuracy)
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import pairwise_distances
class KNNClassifier:
 def __init__(self, k=5, distance='euclidean'):
 self.k = k
 self.distance = distance
 def fit(self, X, y):
 self.X_train = X
 self.y_train = y
 def predict(self, X):
 distances = pairwise_distances(X, self.X_train, metric=self.distance)
 y_pred = [self._predict(dist) for dist in distances]
 return np.array(y_pred)
 def _predict(self, distances):
 k_indices = np.argsort(distances)[:self.k]
 k_nearest_labels = [self.y_train[i] for i in k_indices]
 most_common = max(set(k_nearest_labels), 
key=k_nearest_labels.count)
 return most_common
# Function to evaluate accuracy for a given k and distance metric
def evaluate_knn(k, distance_metrics, x_train, y_train, x_test, y_test):
 accuracies = []
 for distance_metric in distance_metrics:
 knn_classifier = KNNClassifier(k=k, distance=distance_metric)
 knn_classifier.fit(x_train, y_train)
 y_pred = knn_classifier.predict(x_test)
 accuracy = np.mean(y_pred == y_test)
 accuracies.append(accuracy)
 return accuracies
# Define the value of k and distance metrics
k = 20
distance_metrics = ['euclidean', 'manhattan', 'minkowski']
# Evaluate accuracy for the specified k value and distance metrics
accuracies = evaluate_knn(k, distance_metrics, x_train_o.values, 
y_train_o.values, x_test_o.values, y_test_o.values)
print(accuracies)
# Plot results
plt.figure(figsize=(10, 6))
plt.bar(distance_metrics, accuracies)
plt.title(f'Accuracy for k={k} and Different Distance Metrics')
plt.xlabel('Distance Metric')
plt.ylabel('Accuracy')
plt.ylim(0, 1) # Set y-axis limits between 0 and 1
plt.grid(axis='y')
plt.show()
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc
class KNNClassifier:
 def __init__(self, k=5, distance='euclidean'):
 self.k = k
 self.distance = distance
 def fit(self, X, y):
 self.X_train = X
 self.y_train = y
 def predict_proba(self, X):
 distances = pairwise_distances(X, self.X_train, metric=self.distance)
 y_probs = []
 for dist in distances:
 k_indices = np.argsort(dist)[:self.k]
 k_nearest_labels = [self.y_train[i] for i in k_indices]
 class_probs = [k_nearest_labels.count(c) / self.k for c in 
np.unique(self.y_train)]
 y_probs.append(class_probs)
 return np.array(y_probs)
# Function to plot ROC curve
def plot_roc_curve(y_true, y_prob, title):
 fpr, tpr, _ = roc_curve(y_true, y_prob)
 roc_auc = auc(fpr, tpr)
 plt.plot(fpr, tpr, lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
# Function to plot ROC curves for training and testing data on the same 
graph
def plot_roc_curves(classifier, x_train, y_train, x_test, y_test, title):
 classifier.fit(x_train, y_train)
 y_train_prob = classifier.predict_proba(x_train)[:, 1]
 y_test_prob = classifier.predict_proba(x_test)[:, 1]
 plt.figure(figsize=(8, 6))
 plot_roc_curve(y_train, y_train_prob, f'Training {title} ROC Curve')
 plot_roc_curve(y_test, y_test_prob, f'Testing {title} ROC Curve')
 plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
 plt.xlim([0.0, 1.0])
 plt.ylim([0.0, 1.05])
 plt.xlabel('False Positive Rate')
 plt.ylabel('True Positive Rate')
 plt.title('ROC Curves')
 plt.legend(loc="lower right")
 plt.show()
# Instantiate KNN classifier
knn_classifier = KNNClassifier(k=20, distance='euclidean')
# Plot both ROC curves
plot_roc_curves(knn_classifier, x_train_o.values, y_train_o.values, 
x_test_o.values, y_test_o.values, 'KNN Classifier')
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc, pairwise_distances
class KNNClassifier:
 def __init__(self, k=5, distance='euclidean'):
 self.k = k
 self.distance = distance
 def fit(self, X, y):
 self.X_train = X
 self.y_train = y
 def predict_proba(self, X):
 distances = pairwise_distances(X, self.X_train, metric=self.distance)
 y_probs = []
 for dist in distances:
 k_indices = np.argsort(dist)[:self.k]
 k_nearest_labels = [self.y_train[i] for i in k_indices]
 class_probs = [k_nearest_labels.count(c) / self.k for c in 
np.unique(self.y_train)]
 y_probs.append(class_probs)
 return np.array(y_probs)
# Function to plot ROC curve
def plot_roc_curve(y_true, y_prob, title):
 fpr, tpr, _ = roc_curve(y_true, y_prob)
 roc_auc = auc(fpr, tpr)
 plt.plot(fpr, tpr, lw=2, label=f'{title} (area = %0.2f)' % roc_auc)
# Function to plot ROC curves for training and testing data on the same 
graph
def plot_roc_curves(x_train, y_train, x_test, y_test, k=20):
 distance_metrics = ['euclidean', 'manhattan', 'minkowski']
 plt.figure(figsize=(8, 6))
 
 for distance_metric in distance_metrics:
 knn_classifier = KNNClassifier(k=k, distance=distance_metric)
 knn_classifier.fit(x_train, y_train)
 y_train_prob = knn_classifier.predict_proba(x_train)[:, 1]
 y_test_prob = knn_classifier.predict_proba(x_test)[:, 1]
 plot_roc_curve(y_train, y_train_prob, f'Training 
{distance_metric.upper()}')
 plot_roc_curve(y_test, y_test_prob, f'Testing 
{distance_metric.upper()}')
 plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
 plt.xlim([0.0, 1.0])
 plt.ylim([0.0, 1.05])
 plt.xlabel('False Positive Rate')
 plt.ylabel('True Positive Rate')
 plt.title('ROC Curves for Different Distance Metrics')
 plt.legend(loc="lower right")
 plt.show()
# Plot ROC curves for all distance metrics
plot_roc_curves(x_train_o.values, y_train_o.values, x_test_o.values, 
y_test_o.values)